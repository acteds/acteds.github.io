---
layout: post
title: 其他
categories: Java
description: Java笔记
keywords: Java
---

# 引言
一些零散的笔记，XML的读写、JSON的读写、JDBC、GUI。


# XML

XML是可扩展标记语言（eXtensible Markup Language）的缩写，它是一种数据表示格式，可以描述非常复杂的数据结构，常用于传输和存储数据。

例如，一个描述书籍的XML文档可能如下：

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE note SYSTEM "book.dtd">
<book id="1">
    <name>Java核心技术</name>
    <author>Cay S. Horstmann</author>
    <isbn lang="CN">1234567</isbn>
    <tags>
        <tag>Java</tag>
        <tag>Network</tag>
    </tags>
    <pubDate/>
</book>
```

XML有几个特点：一是纯文本，默认使用UTF-8编码，二是可嵌套，适合表示结构化数据。如果把XML内容存为文件，那么它就是一个XML文件，例如`book.xml`。此外，XML内容经常通过网络作为消息传输。

XML有固定的结构，首行必定是`<?xml version="1.0"?>`，可以加上可选的编码。紧接着，如果以类似`<!DOCTYPE note SYSTEM "book.dtd">`声明的是文档定义类型（DTD：Document Type Definition），DTD是可选的。接下来是XML的文档内容，一个XML文档有且仅有一个根元素，根元素可以包含任意个子元素，元素可以包含属性，例如，`<isbn lang="CN">1234567</isbn>`包含一个属性`lang="CN"`，且元素必须正确嵌套。如果是空元素，可以用`<tag/>`表示。

由于使用了`<`、`>`以及引号等标识符，如果内容出现了特殊符号，需要使用`&???;`表示转义。例如，`Java<tm>`必须写成：

```
<name>Java&lt;tm&gt;</name>
```

常见的特殊字符如下：

| 字符 | 表示   |
| :--- | :----- |
| <    | `&lt;`   |
| >    | `&gt;`   |
| &    | `&amp;`  |
| "    | `&quot;` |
| '    | `&apos;` |

格式正确的XML（Well Formed）可以被解析器正常读取。而合法的XML是指，不但XML格式正确，而且它的数据结构可以被DTD或者XSD验证。

DTD文档可以指定一系列规则，例如：

- 根元素必须是`book`
- `book`元素必须包含`name`，`author`等指定元素
- `isbn`元素必须包含属性`lang`
- ...

如何验证XML文件的正确性呢？最简单的方式是通过浏览器验证。可以直接把XML文件拖拽到浏览器窗口，如果格式错误，浏览器会报错。

和结构类似的HTML不同，浏览器对HTML有一定的“容错性”，缺少关闭标签也可以被解析，但XML要求严格的格式，任何没有正确嵌套的标签都会导致错误。

XML是一个技术体系，除了经常用到的XML文档本身外，XML还支持：

- DTD和XSD：验证XML结构和数据是否有效；
- Namespace：XML节点和属性的名字空间；
- XSLT：把XML转化为另一种文本；
- XPath：一种XML节点查询语言；
- ...



因为XML是一种树形结构的文档，它有两种标准的解析API：

- DOM：一次性读取XML，并在内存中表示为树形结构；
- SAX：以流的形式读取XML，使用事件回调。

## 使用DOM解析

DOM是Document Object Model的缩写，DOM模型就是把XML结构作为一个树形结构处理，从根节点开始，每个节点都可以包含任意个子节点。

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<book id="1">
    <name>Java核心技术</name>
    <author>Cay S. Horstmann</author>
    <isbn lang="CN">1234567</isbn>
    <tags>
        <tag>Java</tag>
        <tag>Network</tag>
    </tags>
    <pubDate/>
</book>
```

`document`代表XML文档，是真正的“根”，而`<book>`虽然是根元素，但它是`document`的一个子节点。

Java提供了DOM API来解析XML，它使用下面的对象来表示XML的内容：

- Document：代表整个XML文档；
- Element：代表一个XML元素；
- Attribute：代表一个元素的某个属性。

使用DOM解析一个XML文档的代码如下：

```java
package test;

import org.junit.jupiter.api.Test;
import org.w3c.dom.Document;
import org.w3c.dom.NamedNodeMap;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;
import org.xml.sax.SAXException;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;
import java.io.IOException;
import java.io.InputStream;

public class DemoTest {
    @Test
    void testNegative() throws IOException, SAXException, ParserConfigurationException {
        // 从文件、网络流或其他来源获取 XML 输入流
        InputStream input = DemoTest.class.getResourceAsStream("book.xml");
        DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
        DocumentBuilder db = dbf.newDocumentBuilder();
        // 使用 DocumentBuilder 解析输入流，获取 Document 实例
        Document doc = db.parse(input);
        printNode(doc,0);
    }
    void printNode(Node n, int indent) {
        switch (n.getNodeType()) {
            case Node.DOCUMENT_NODE: // Document节点
                System.out.println(getRetraction(indent)+"Document: " + n.getNodeName());
                break;
            case Node.ELEMENT_NODE: // 元素节点
                System.out.println(getRetraction(indent)+"Element: " + n.getNodeName());
                break;
            case Node.TEXT_NODE: // 文本
                if (n.getNodeValue().matches("\\s+")){//为空则无视
                    break;
                }
                System.out.println(getRetraction(indent)+"Text = " + n.getNodeValue());
                break;
            case Node.ATTRIBUTE_NODE: // 属性
                System.out.println(getRetraction(indent)+"Attr: " + n.getNodeName() + " = " + n.getNodeValue());
                break;

            case Node.CDATA_SECTION_NODE:// 非解析文本
                System.out.println(getRetraction(indent)+ "CDATA: " + n.getNodeValue().trim());
                break;
            case Node.COMMENT_NODE:// 注释
                System.out.println(getRetraction(indent)+ "Comment: " + n.getNodeValue().trim());
                break;
            default: // 其他
                System.out.println(getRetraction(indent)+"NodeType: " + n.getNodeType() + ", NodeName: " + n.getNodeName());
        }
        if (n.hasAttributes()) {//有属性则递归
            NamedNodeMap as = n.getAttributes();// 获取标签内所有属性
            for (int i = 0; i < as.getLength(); i++) {
                printNode(as.item(i), indent+2);// 递归
            }
        }
        if (n.hasChildNodes()) {//有子节点则递归
            NodeList childNodes = n.getChildNodes();
            for (int i = 0; i < childNodes.getLength(); i++) {
                printNode(childNodes.item(i), indent+2);// 递归
            }
        }

    }

    private static String getRetraction(int indent) {
        StringBuilder s= new StringBuilder();
        for (int i = 0; i < indent; i++) {
            s.append(" ");
        }
        return s.toString();
    }
}
```

`DocumentBuilder.parse()`用于解析一个XML，它可以接收`InputStream`，`File`或者`URL`，如果解析无误，将获得一个`Document`对象，这个对象代表了整个`XML`文档的树形结构。

从根节点`Document`出发，可以遍历所有子节点，获取所有元素、属性、文本数据，还可以包括注释，这些节点被统称为`Node`，每个`Node`都有自己的`Type`，根据`Type`来区分一个`Node`到底是元素，还是属性，还是文本，等等。

使用DOM API时，如果要读取某个元素的文本，需要访问它的Text类型的子节点，所以使用起来还是比较繁琐的，且DOM解析速度慢，内存占用大。

------

`org.w3c.dom.Document` 接口表示整个 XML 文档，它是 DOM（Document Object Model） API 的核心接口之一。`Document` 对象提供了操作 XML 文档的方法，允许您访问和修改文档中的元素、属性和文本内容等。`Document` 接口定义了一些独有的方法：

- `Element getDocumentElement()`: 返回文档的根元素。
- `Element createElement(String tagName)`: 创建具有指定标签名称的新元素。
- `Text createTextNode(String data)`: 创建包含指定数据的新文本节点。
- `Attr createAttribute(String name)`: 创建具有指定名称的新属性节点。
- `Element getElementById(String elementId)`: 返回具有指定 ID 的元素。
- `Element createElementNS(String namespaceURI, String qualifiedName)`: 使用指定的命名空间URI和限定名称创建新元素。
- `Attr createAttributeNS(String namespaceURI, String qualifiedName)`: 使用指定的命名空间URI和限定名称创建新属性。
- `Node importNode(Node importedNode, boolean deep)`: 将节点从另一个文档导入到当前文档。

------

`org.w3c.dom.Node` 接口表示 DOM（Document Object Model）树中的一个节点，它是 DOM API 的核心接口之一。`Node` 接口定义了节点的通用属性和方法，所有 DOM 节点类型都实现了该接口，包括元素节点、文本节点、注释节点等。`Node` 接口的主要作用是：

1. **表示 DOM 树中的一个节点：** `Node` 接口表示 DOM 树中的一个节点，每个节点可以是一个元素、属性、文本内容、注释等。
2. **提供访问节点的方法：** `Node` 接口提供了一系列方法，用于访问和操作节点的属性、子节点和父节点等。
3. **定义节点类型：** `Node` 接口定义了表示不同类型节点的常量，如 `ELEMENT_NODE`、`TEXT_NODE`、`COMMENT_NODE` 等。
4. **节点关系：** `Node` 接口提供了方法来获取节点的父节点、子节点、兄弟节点等关系信息。
5. **节点操作：** `Node` 接口提供了方法来添加、移除、替换节点，以及克隆节点等操作。

以下是一些常用的 `Node` 接口方法：

1. **获取节点信息：**
   - **`String getNodeName()`: 返回节点的名称。**
   - **`String getNodeValue()`: 返回节点的值（仅适用于特定类型的节点，如文本节点）。**
   - **`short getNodeType()`: 返回节点的类型（例如，元素节点、文本节点等）。**
2. **获取父节点和子节点：**
   - `Node getParentNode()`: 返回父节点。
   - **`NodeList getChildNodes()`: 返回子节点列表。**
   - `Node getFirstChild()`: 返回第一个子节点。
   - `Node getLastChild()`: 返回最后一个子节点。
   - `Node getNextSibling()`: 返回下一个兄弟节点。
   - `Node getPreviousSibling()`: 返回上一个兄弟节点。
3. **操作节点：**
   - `Node appendChild(Node newChild)`: 将节点添加为最后一个子节点。
   - `Node removeChild(Node oldChild)`: 从子节点列表中删除指定的子节点。
   - `Node replaceChild(Node newChild, Node oldChild)`: 用新节点替换指定的子节点。
4. **判断节点关系：**
   - **`boolean hasChildNodes()`: 判断节点是否有子节点。**
   - **`boolean hasAttributes()`：判断节点是否有属性。**
   - `boolean isSameNode(Node other)`: 判断节点是否与另一个节点相同。
5. **其他方法：**
   - `Node cloneNode(boolean deep)`: 复制节点（如果 `deep` 为 true，则同时复制子树）。
   - `Document getOwnerDocument()`: 返回拥有当前节点的文档节点。
6. **获取属性节点：**
   - **`NamedNodeMap getAttributes()`: 返回包含节点所有属性的 `NamedNodeMap` 对象。**
7. **获取特定属性：**
   - `Node getAttributeNode(String name)`: 返回具有指定名称的属性节点。
   - `String getAttribute(String name)`: 返回具有指定名称的属性的值。
8. **添加和移除属性：**
   - `void setAttribute(String name, String value)`: 设置具有指定名称和值的属性。如果属性已存在，则替换旧值。
   - `void removeAttribute(String name)`: 删除具有指定名称的属性。
9. **判断属性是否存在：**
   - `boolean hasAttribute(String name)`: 判断节点是否具有指定名称的属性。



在 DOM（文档对象模型）中，不同类型的节点用不同的常量值表示，以便于区分节点的类型。这些常量由 `Node` 接口定义，可以通过 `Node` 接口的静态常量来访问。常见的节点类型包括：

- `Node.ELEMENT_NODE`：表示元素节点。
- `Node.ATTRIBUTE_NODE`：表示属性节点。
- `Node.TEXT_NODE`：表示文本节点。
- `Node.COMMENT_NODE`：表示注释节点。
- `Node.DOCUMENT_NODE`：表示文档节点。

`Node.DOCUMENT_NODE` 表示整个文档的根节点，即文档对象（Document Object）。在 DOM 中，文档对象是整个 XML 或 HTML 文档的入口点，通过文档对象可以访问文档的所有内容，包括元素、属性、文本等。通常，使用 `Document` 类型的实例表示文档对象。

例如，可以通过以下方式检查一个节点是否为文档节点：

```java
Node node = ...; // 获取一个节点
if (node.getNodeType() == Node.DOCUMENT_NODE) {
    // 这是一个文档节点
    Document document = (Document) node;
    // 可以对文档进行操作
}
```

通过比较节点的类型是否为 `Node.DOCUMENT_NODE`，可以判断节点是否为文档节点，从而进行相应的操作。

如果对`Document`进行了修改，要保存，则可以将修改后的内容保存到文件或其他输出流中。保存 `Document` 的常用方法是将其转换为字符串形式，然后将字符串写入文件或输出流中。

下面是一个简单的示例，演示了如何将修改后的 `Document` 保存到文件中：

```java
// 从文件、网络流或其他来源获取 XML 输入流
InputStream input = DemoTest.class.getResourceAsStream("book.xml");
DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
DocumentBuilder db = dbf.newDocumentBuilder();
// 使用 DocumentBuilder 解析输入流，获取 Document 实例
Document doc = db.parse(input);
// 创建一个 Transformer 对象
Transformer transformer = TransformerFactory.newInstance().newTransformer();
DOMSource source = new DOMSource(doc);
// 将字符串写入文件中
StreamResult result = new StreamResult(new File("1.xml"));
// 使用 Transformer 将 Document 转换为字符串形式
transformer.transform(source, result);
```

## 使用SAX解析

使用DOM解析XML的优点是用起来省事，但它的主要缺点是内存占用太大。

另一种解析XML的方式是SAX。SAX是Simple API for XML的缩写，它是一种基于流的解析方式，边读取XML边解析，并以事件回调的方式让调用者获取数据。因为是一边读一边解析，所以无论XML有多大，占用的内存都很小。

SAX解析会触发一系列事件：

- startDocument：开始读取XML文档；
- startElement：读取到了一个元素，例如`<book>`；
- characters：读取到了字符；
- endElement：读取到了一个结束的元素，例如`</book>`；
- endDocument：读取XML文档结束。

如果用SAX API解析XML，Java代码如下：

```java
InputStream input = DemoTest.class.getResourceAsStream("book.xml");
SAXParserFactory spf = SAXParserFactory.newInstance();
SAXParser saxParser = spf.newSAXParser();
saxParser.parse(input, new MyHandler());
```

关键代码`SAXParser.parse()`除了需要传入一个`InputStream`外，还需要传入一个回调对象，这个对象要继承自`DefaultHandler`：

```java
static class MyHandler extends DefaultHandler {
    public void startDocument() {
        print("文档开始");
    }
    public void endDocument() {
        print("文档结束");
    }
    public void startElement(String uri, String localName, String qName, Attributes attributes) {
        print("元素：", localName, qName);
        print("属性:");
        for (int i = 0; i < attributes.getLength(); i++) {
            print("  ",attributes.getLocalName(i),"=",attributes.getValue(i));
        }
    }
    public void endElement(String uri, String localName, String qName) {
        print("元素结束:", localName, qName);
    }
    public void characters(char[] ch, int start, int length) {
        print("文本:", new String(ch, start, length));
    }
    public void error(SAXParseException e) {
        print("错误:", e);
    }
    void print(Object... objs) {
        for (Object obj : objs) {
            System.out.print(obj);
            System.out.print(" ");
        }
        System.out.println();
    }
}
```

如果要读取`<name>`节点的文本，我们就必须在解析过程中根据`startElement()`和`endElement()`定位当前正在读取的节点，可以使用栈结构保存，每遇到一个`startElement()`入栈，每遇到一个`endElement()`出栈，这样，读到`characters()`时我们才知道当前读取的文本是哪个节点的。可见，使用SAX API仍然比较麻烦。

SAX是一种流式解析XML的API；SAX通过事件触发，读取速度快，消耗内存少；调用方必须通过回调方法获得解析过程中的数据。

------

要创建 `SAXParser` 对象，通常使用 `SAXParserFactory` 工厂类：

```java
// 创建 SAXParserFactory 实例
SAXParserFactory factory = SAXParserFactory.newInstance();
// 指定是否验证 XML 文件，默认为 false
factory.setValidating(false);
// 指定是否命名空间感知，默认为 false
factory.setNamespaceAware(false);
// 创建 SAXParser 实例
SAXParser saxParser = factory.newSAXParser();
```

`SAXParser` 类是用于解析 `XML` 文档的类，它实现了 `XMLReader` 接口，提供了一系列方法来解析 `XML` 文档。以下是 `SAXParser` 类的一些常用方法：

- `parse(InputSource input, DefaultHandler handler)`：解析给定的输入源并使用指定的处理程序处理 `XML` 内容。
- **`parse(InputStream is, DefaultHandler dh)`：解析给定的输入流并使用指定的处理程序处理 `XML` 内容。**
- `parse(File f, DefaultHandler dh)`：解析给定的文件并使用指定的处理程序处理 `XML` 内容。
- `parse(String uri, DefaultHandler dh)`：解析给定的 `URI` 并使用指定的处理程序处理 `XML` 内容。
- `setContentHandler(ContentHandler handler)`：设置内容处理程序，用于处理 `XML` 文档中的内容。
- `setDTDHandler(DTDHandler handler)`：设置 `DTD` 处理程序，用于处理 `XML` 文档中的 `DTD` 声明。
- `setEntityResolver(EntityResolver resolver)`：设置实体解析器，用于解析 `XML` 文档中的实体。
- `setErrorHandler(ErrorHandler handler)`：设置错误处理程序，用于处理 `XML` 解析过程中的错误。
- `getXMLReader()`：获取与此 `SAXParser` 关联的 `XMLReader` 对象，用于解析 `XML` 文档。
- `getSchema()`：获取当前为 `SAXParser` 设置的 `XML Schema`。
- `isNamespaceAware()`：返回解析器是否为命名空间感知的布尔值。
- `isValidating()`：返回解析器是否验证 `XML` 内容的布尔值。

这些方法用于配置和操作 `SAXParser` 实例，以便解析 `XML` 文档并处理其内容。

`DefaultHandler` 是 `SAX` 解析器的默认处理程序，它实现了 `ContentHandler`、`DTDHandler`、`EntityResolver` 和 `ErrorHandler` 接口。这些接口定义了处理 `XML` 内容和解析过程中可能出现的各种情况的方法。以下是 `DefaultHandler` 中一些重要的方法和作用：

- **`startDocument()`：在解析文档开始时调用。**
- **`endDocument()`：在解析文档结束时调用。**
- **`startElement(String uri, String localName, String qName, Attributes attributes)`：在解析元素开始时调用。**
- **`endElement(String uri, String localName, String qName)`：在解析元素结束时调用。**
- **`characters(char[] ch, int start, int length)`：在解析字符数据时调用。**
- `startPrefixMapping(String prefix, String uri)`：在解析命名空间前缀映射时调用。
- `endPrefixMapping(String prefix)`：在解析命名空间前缀映射结束时调用。
- `processingInstruction(String target, String data)`：在解析处理指令时调用。
- `skippedEntity(String name)`：在解析实体时调用。
- `warning(SAXParseException e)`：在解析过程中遇到警告时调用。
- **`error(SAXParseException e)`：在解析过程中遇到可恢复错误时调用。**
- `fatalError(SAXParseException e)`：在解析过程中遇到致命错误时调用。

`DefaultHandler` 的作用是提供这些方法的默认实现，可以根据需要覆盖这些方法来处理 `XML` 解析过程中的事件。通常，可以创建一个继承自 `DefaultHandler` 的类，并重写其中的方法来实现自定义的 `XML` 处理逻辑。

`SAXParser` 本身并不能直接修改 `XML`，因为 `SAXParser` 是一种流式解析器，它按顺序读取 `XML` 文件并触发相应的事件，而不会将整个 `XML` 文档加载到内存中。因此，如果需要修改 `XML`，通常需要借助其他 `API` 或方法来实现。

## 使用StAX解析

StAX（Streaming API for XML）是用于处理 XML 的一种流式处理 API。与传统的 DOM（Document Object Model）和 SAX（Simple API for XML）相比，StAX 提供了一种更灵活的方式来读取和写入 XML 数据。

使用 StAX，可以逐个事件地处理 XML 文档，而不需要将整个文档加载到内存中（像 DOM 那样），也不需要像 SAX 那样完全依赖事件回调模型。相反，StAX 允许以迭代器的方式逐个读取或写入 XML 元素，使得处理 XML 数据变得更加简单和高效。

```java
InputStream input = DemoTest.class.getResourceAsStream("book.xml");
XMLInputFactory factory = XMLInputFactory.newInstance();
XMLStreamReader reader = factory.createXMLStreamReader(input);

while (reader.hasNext()) {
    int event = reader.next();
    switch (event) {
        case XMLStreamConstants.START_ELEMENT:
            System.out.println("元素： " + reader.getLocalName());
            for (int i = 0; i < reader.getAttributeCount(); i++) {
                System.out.println("  Attribute: " + reader.getAttributeLocalName(i) + "=" + reader.getAttributeValue(i));
            }
            break;
        case XMLStreamConstants.CHARACTERS:
            if (!reader.isWhiteSpace()) {
                System.out.println("文本: " + reader.getText());
            }
            break;
        case XMLStreamConstants.END_ELEMENT:
            System.out.println("元素结束: " + reader.getLocalName());
            break;
    }
}
reader.close();
input.close();
```

要使用 StAX 修改 XML，需要创建一个 `XMLInputFactory` 来读取 XML 文件，并创建一个 `XMLOutputFactory` 来写入修改后的 XML。示例：

```java
Deque<String> stack=new LinkedList<>();
// 创建输入和输出的 XML 工厂
XMLInputFactory inputFactory = XMLInputFactory.newInstance();
XMLOutputFactory outputFactory = XMLOutputFactory.newInstance();

// 创建 XML 输入和输出流
InputStream input = DemoTest.class.getResourceAsStream("book.xml");
OutputStream output = new FileOutputStream("book2.xml");
XMLStreamReader reader = inputFactory.createXMLStreamReader(input);
XMLStreamWriter writer = outputFactory.createXMLStreamWriter(output);
writer.writeStartDocument("UTF-8", "1.0"); // 写入XML声明
// 处理元素
while (reader.hasNext()) {
    int event = reader.next();
    switch (event) {
        case XMLStreamConstants.START_ELEMENT:
            // 处理开始元素
            String elementName = reader.getLocalName();
            stack.push(elementName);
            if ("book".equals(elementName)) {
                // 修改元素内容
                writer.writeStartElement("book2");
            } else {
                // 复制其他元素
                writer.writeStartElement(elementName);
            }
            for (int i = 0; i < reader.getAttributeCount(); i++) {
                writer.writeAttribute(reader.getAttributeLocalName(i),reader.getAttributeValue(i));
            }
            break;

        case XMLStreamConstants.CHARACTERS:
            if (!reader.isWhiteSpace()) {
                if("isbn".equals(stack.peek())){
                    writer.writeCharacters("666888");
                }else {
                    writer.writeCharacters(reader.getText());
                }
            }
            break;
        case XMLStreamConstants.END_ELEMENT:
            stack.pop();
            writer.writeEndElement();
            break;
    }
}

// 关闭流
reader.close();
writer.close();
input.close();
output.close();
```

这段代码的目标是读取一个 XML 文件并将其内容修改后写入另一个 XML 文件。在处理元素内容时，如果当前元素是 `isbn`，则将其内容修改为 "666888"，如果当前元素是`book`则修改为`book2`。

------

`XMLStreamReader` 是用于读取 XML 数据的接口，它允许逐个事件地读取 XML 文档的内容，并提供了一种低级别的、基于流的方式来解析 XML。通过 `XMLStreamReader`，可以逐步遍历 XML 文档的元素、属性、文本内容等，并根据需要对文档进行处理，如提取数据、修改内容等操作。这种基于流的解析方式相比于基于文档对象模型（DOM）的解析方式，更加高效，尤其适用于处理大型 XML 文件。

`XMLStreamReader` 提供了许多方法来读取 XML 文档的不同部分，以下是一些常用的方法：

- **`boolean hasNext()`：检查是否还有更多的事件要处理。**
- **`int next()`：移动到下一个 XML 事件，并返回事件的类型。**
- `int getEventType()`：返回当前事件的类型。
- `boolean isStartElement()`：检查当前事件是否是开始元素。
- `boolean isCharacters()`：检查当前事件是否是字符数据。
- `boolean isEndElement()`：检查当前事件是否是结束元素。
- `String getLocalName()`：返回当前元素的本地名称。
- **`int getAttributeCount()`：返回当前元素的属性数。**
- **`String getAttributeLocalName(int index)`：返回指定索引处属性的本地名称。**
- **`String getAttributeValue(int index)`：返回指定索引处属性的值。**
- **`String getText()`：返回当前元素的文本内容。**
- **`boolean isWhiteSpace()`：检查当前解析器位置是否位于空白字符上。**
- **`void close()`：关闭 `XMLStreamReader`。**

这些方法可以在处理 XML 文档时导航并提取所需的信息。

------

`XMLStreamWriter` 是用于写入 XML 数据的接口，它允许逐个事件地生成 XML 文档的内容，并提供了一种低级别的、基于流的方式来生成 XML。通过 `XMLStreamWriter`，可以逐步构建 XML 文档的元素、属性、文本内容等，并生成符合 XML 规范的 XML 数据。这种基于流的生成方式相比于基于文档对象模型（DOM）的生成方式，更加高效，尤其适用于生成大型 XML 文件。

常用的 `XMLStreamWriter` 方法包括：

- **`writeStartDocument(String version, String encoding)`：写入 XML 声明。**
- **`writeStartElement(String localName)`：写入开始元素。**
- **`writeAttribute(String localName, String value)`：写入元素属性。**
- **`writeCharacters(String text)`：写入文本内容。**
- **`writeEndElement()`：写入结束元素。**
- `writeEndDocument()`：写入 XML 结束标记。
- `flush()`：刷新缓冲区，确保所有数据都被写入底层流。
- **`close()`：关闭 `XMLStreamWriter`。**

------

`XMLStreamConstants` 是一个接口，定义了一组整数常量，用于表示 XML 解析器生成的各种事件类型。这些常量用于与 `XMLStreamReader` 和 `XMLStreamWriter` 一起使用，以便在处理 XML 文档时识别不同类型的事件。通过这些常量，可以方便地检查当前事件的类型，并根据需要执行相应的操作。

`XMLStreamConstants` 提供了以下常量：

- `START_ELEMENT`：表示开始元素事件。
- `END_ELEMENT`：表示结束元素事件。
- `CHARACTERS`：表示字符数据事件。
- `ATTRIBUTE`：表示属性事件。
- `NAMESPACE`：表示命名空间事件。
- `START_DOCUMENT`：表示开始文档事件。
- `END_DOCUMENT`：表示结束文档事件。
- `PROCESSING_INSTRUCTION`：表示处理指令事件。
- `COMMENT`：表示注释事件。
- `DTD`：表示 DTD 事件。
- `ENTITY_REFERENCE`：表示实体引用事件。
- `CDATA`：表示 CDATA 事件。
- `SPACE`：表示空格事件。



## 使用Jackson

XML文档的结构：

```xml
<?xml version="1.0" encoding="UTF-8" ?>
<book id="1">
    <name>Java核心技术</name>
    <author>Cay S. Horstmann</author>
    <isbn lang="CN">1234567</isbn>
    <tags>
        <tag>Java</tag>
        <tag>Network</tag>
    </tags>
    <pubDate/>
</book>
```

完全可以对应到一个定义好的JavaBean中：

```java
public class Book {
    public long id;
    public String name;
    public String author;
    public String isbn;
    public List<String> tags;
    public String pubDate;
}
```

Jackson第三方库可以轻松做到XML到JavaBean的转换。要使用Jackson，先添加一个Maven的依赖：

```xml
<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.dataformat/jackson-dataformat-xml -->
<dependency>
    <groupId>com.fasterxml.jackson.dataformat</groupId>
    <artifactId>jackson-dataformat-xml</artifactId>
    <version>2.17.0</version>
</dependency>
```

然后，定义好JavaBean，就可以用下面几行代码解析：

```java
InputStream input = Main.class.getResourceAsStream("/book.xml");
JacksonXmlModule module = new JacksonXmlModule();
XmlMapper mapper = new XmlMapper(module);
Book book = mapper.readValue(input, Book.class);
System.out.println(book.id);
System.out.println(book.name);
System.out.println(book.author);
System.out.println(book.isbn);
System.out.println(book.tags);
System.out.println(book.pubDate);
```

`XmlMapper`可以用`readValue(InputStream, Class)`直接读取XML并返回一个JavaBean。运行上述代码，就可以直接从Book对象中拿到数据：

```text
1
Java核心技术
Cay S. Horstmann
1234567
[Java, Network]
null
```

如果要解析的数据格式不是`Jackson`内置的标准格式，那么需要编写一点额外的扩展来告诉`Jackson`如何自定义解析，可以参考[Jackson](https://github.com/FasterXML/jackson)的[官方文档](https://github.com/FasterXML/jackson-annotations)。读取属性：

```java
package test;

import com.fasterxml.jackson.databind.MapperFeature;
import com.fasterxml.jackson.dataformat.xml.JacksonXmlModule;
import com.fasterxml.jackson.dataformat.xml.XmlMapper;
import com.fasterxml.jackson.dataformat.xml.annotation.JacksonXmlProperty;
import com.fasterxml.jackson.dataformat.xml.annotation.JacksonXmlText;
import org.junit.jupiter.api.Test;

import java.io.IOException;
import java.io.InputStream;
import java.util.List;

public class DemoTest {
    @Test
    void testNegative() throws IOException {
        InputStream input = DemoTest.class.getResourceAsStream("book.xml");
        JacksonXmlModule module = new JacksonXmlModule();
        // 默认使用“未包装”列表:
        //module.setDefaultUseWrapper(false);
        XmlMapper mapper = new XmlMapper(module);
        //自动忽略无法对应pojo的字段
        //mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        //字段为null，自动忽略，不再序列化
        //mapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);
        //XML标签名:使用骆驼命名的属性名，
        //mapper.setPropertyNamingStrategy(PropertyNamingStrategy.UPPER_CAMEL_CASE);
        //设置转换模式
        mapper.enable(MapperFeature.USE_STD_BEAN_NAMING);
        Book book = mapper.readValue(input, Book.class);
        System.out.println(book.id);
        System.out.println(book.name);
        System.out.println(book.author);
        System.out.println("节点isbn的值为:" + book.isbn.value);
        System.out.println("节点isbn的属性lang的值为:" + book.isbn.lang);
        System.out.println("节点isbn的属性aa的值为:" + book.isbn.aa);
        System.out.println(book.tags);
        System.out.println(book.pubDate);
    }
}
class Book {
    public long id;
    public String name;
    public String author;
    @JacksonXmlProperty(localName = "isbn")
    public BookAttr isbn;
    public List<String> tags;
    public String pubDate;
}
class BookAttr {
    @JacksonXmlProperty(isAttribute = true, localName = "lang")
    public String lang;
    @JacksonXmlProperty(isAttribute = true, localName = "aa")
    public String aa;
    //测试一下
    @JacksonXmlText
    public String value;
}
```

# JSON

XML的特点是功能全面，但标签繁琐，格式复杂。在Web上使用XML现在越来越少，取而代之的是JSON这种数据结构。

JSON是JavaScript Object Notation的缩写，它去除了所有JavaScript执行代码，只保留JavaScript的对象格式。一个典型的JSON如下：

```javascript
{
    "id": 1,
    "name": "Java核心技术",
    "author": {
        "firstName": "Abc",
        "lastName": "Xyz"
    },
    "isbn": "1234567",
    "tags": ["Java", "Network"]
}
```

JSON作为数据传输的格式，有几个显著的优点：

- JSON只允许使用UTF-8编码，不存在编码问题；
- JSON只允许使用双引号作为key，特殊字符用`\`转义，格式简单；
- 浏览器内置JSON支持，如果把数据用JSON发送给浏览器，可以用JavaScript直接处理。

因此，JSON适合表示层次结构，因为它格式简单，仅支持以下几种数据类型：

- 键值对：`{"key": value}`
- 数组：`[1, 2, 3]`
- 字符串：`"abc"`
- 数值（整数和浮点数）：`12.34`
- 布尔值：`true`或`false`
- 空值：`null`

浏览器直接支持使用JavaScript对JSON进行读写：

```javascript
// JSON string to JavaScript object:
jsObj = JSON.parse(jsonStr);

// JavaScript object to JSON string:
jsonStr = JSON.stringify(jsObj);
```

开发Web应用的时候，使用JSON作为数据传输，在浏览器端非常方便。因为JSON天生适合JavaScript处理，绝大多数REST API都选择JSON作为数据传输格式。

在Java中，针对JSON也有标准的JSR 353 API。常用的用于解析JSON的第三方库有：`Jackson`、`Gson`、`Fastjson`。

使用`Jackson`：

```xml
<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.dataformat/jackson-dataformat-xml -->
<dependency>
    <groupId>com.fasterxml.jackson.dataformat</groupId>
    <artifactId>jackson-dataformat-xml</artifactId>
    <version>2.17.0</version>
</dependency>
```

就可以使用下面的代码解析一个JSON文件：

```java
public class DemoTest {
    @Test
    void testNegative() throws IOException {
        InputStream input = DemoTest.class.getResourceAsStream("book.json");
        System.out.println(input);
        ObjectMapper mapper = new ObjectMapper();
        // 反序列化时忽略不存在的JavaBean属性:
        mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        Book book = mapper.readValue(input, Book.class);
        System.out.println(book);
    }
}
class Book {
    public long id;
    public String name;
    public Map<String,String> author;
    public String isbn;
    public List<String> tags;

    @Override
    public String toString() {return "Book{id=" + id + ", name='" + name + '\'' + ", author=" + author + ", isbn='" + isbn + '\'' + ", tags=" + tags + '}'; }
}
```

核心代码是创建一个`ObjectMapper`对象。关闭`DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES`功能使得解析时如果JavaBean不存在该属性时解析不会报错。

还可以直接用Map接收：

```java
InputStream input = DemoTest.class.getResourceAsStream("book.json");
System.out.println(input);
ObjectMapper mapper = new ObjectMapper();
Map<String, Object> map = mapper.readValue(input, Map.class);
System.out.println(map);
```

------

把JSON解析为JavaBean的过程称为反序列化。如果把JavaBean变为JSON，那就是序列化。要实现JavaBean到JSON的序列化，只需要一行代码：

```java
String json = mapper.writeValueAsString(book);
```

还可以生成带缩进和换行的JSON：

```java
String json=mapper.writerWithDefaultPrettyPrinter().writeValueAsString(map);
```



------

要把JSON的某些值解析为特定的Java对象，例如`LocalDate`，也是完全可以的。例如：

```javascript
{
    "name": "Java核心技术",
    "pubDate": "2016-09-01"
}
```

要解析为：

```java
public class Book {
    public String name;
    public LocalDate pubDate;
}
```

只需要引入标准的JSR 310关于`JavaTime`的数据格式定义至Maven：

```xml
<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.datatype/jackson-datatype-jsr310 -->
<dependency>
    <groupId>com.fasterxml.jackson.datatype</groupId>
    <artifactId>jackson-datatype-jsr310</artifactId>
    <version>2.17.0</version>
</dependency>
```

然后，在创建`ObjectMapper`时，注册一个新的`JavaTimeModule`：

```java
ObjectMapper mapper = new ObjectMapper().registerModule(new JavaTimeModule());
```

还可以自定义解析，假设`Book`类的`isbn`是一个`BigInteger`：

```java
public class Book {
	public String name;
	public BigInteger isbn;
}
```

但JSON数据并不是标准的整形格式：

```java
{
    "name": "Java核心技术",
    "isbn": "978-7-111-54742-6"
}
```

直接解析，肯定报错。这时，需要自定义一个`IsbnDeserializer`，用于解析含有非数字的字符串：

```java
public class IsbnDeserializer extends JsonDeserializer<BigInteger> {
    public BigInteger deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException {
        // 读取原始的JSON字符串内容:
        String s = p.getValueAsString();
        if (s != null) {
            try {
                return new BigInteger(s.replace("-", ""));
            } catch (NumberFormatException e) {
                throw new JsonParseException(p, s, e);
            }
        }
        return null;
    }
}
```

然后，在`Book`类中使用注解标注：

```java
public class Book {
    public String name;
    // 表示反序列化isbn时使用自定义的IsbnDeserializer:
    @JsonDeserialize(using = IsbnDeserializer.class)
    public BigInteger isbn;
}
```

类似的，自定义序列化时我们需要自定义一个`IsbnSerializer`，然后在`Book`类中标注`@JsonSerialize(using = ...)`即可。

在反序列化时，`Jackson`要求Java类**需要一个默认的无参数构造方法**，否则，无法直接实例化此类。存在带参数构造方法的类，如果要反序列化，注意再提供一个无参数构造方法。

对于`enum`字段，Jackson按String类型处理，即：

```java
class Book {
    public DayOfWeek start = MONDAY;
}
```

序列化为：

```javascript
{
    "start": "MONDAY"
}
```

对于`record`类型（**Java 14** ），Jackson会自动找出它的带参数构造方法，并根据JSON的key进行匹配，可直接反序列化。对`record`类型的支持需要版本`2.12.0`以上。



# JDBC

Java为关系数据库定义了一套标准的访问接口：JDBC（Java Database Connectivity）

使用Java程序访问数据库时，Java代码并不是直接通过TCP连接去访问数据库，而是通过JDBC接口来访问，而JDBC接口则通过JDBC驱动来实现真正对数据库的访问。

在Java代码中如果要访问MySQL，必须编写代码操作JDBC接口。JDBC接口是Java标准库自带的，所以可以直接编译。而具体的JDBC驱动是由数据库厂商提供的，例如，MySQL的JDBC驱动由Oracle提供。因此，访问某个具体的数据库，只需要引入该厂商提供的JDBC驱动，就可以通过JDBC接口来访问，这样保证了Java程序编写的是一套数据库访问代码，却可以访问各种不同的数据库，因为他们都提供了标准的JDBC驱动。

从代码来看，Java标准库自带的JDBC接口其实就是定义了一组接口，而某个具体的JDBC驱动其实就是实现了这些接口的类。

一个MySQL的JDBC的驱动就是一个jar包，本身也是纯Java编写的。编写的代码只需要引用Java标准库提供的`java.sql`包下面的相关接口，由此再间接地通过MySQL驱动的jar包通过网络访问MySQL服务器，所有复杂的网络通讯都被封装到JDBC驱动中，因此，Java程序本身只需要引入一个MySQL驱动的jar包就可以正常访问MySQL服务器

使用JDBC的好处是：

- 各数据库厂商使用相同的接口，Java代码不需要针对不同数据库分别开发；
- Java程序编译期仅依赖java.sql包，不依赖具体数据库的jar包；
- 可随时替换底层数据库，访问数据库的Java代码基本不变。

mysql的JDBC驱动：

```xml
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>5.1.47</version>
    <scope>runtime</scope>
</dependency>
```

依赖的`scope`是`runtime`，因为编译Java程序并不需要MySQL的这个jar包，只有在运行期才需要使用。如果把`runtime`改成`compile`，虽然也能正常编译，但是在IDE里写程序的时候，会多出来一大堆类似`com.mysql.jdbc.Connection`这样的类，非常容易与Java标准库的JDBC接口混淆，所以坚决不要设置为`compile`。

##  连接数据库

`Connection`代表一个JDBC连接，它相当于Java程序到数据库的连接（通常是TCP连接）。打开一个`Connection`时，需要准备URL、用户名和口令，才能成功连接到数据库。

URL是由数据库厂商指定的格式，例如，MySQL的URL是：

```text
jdbc:mysql://<hostname>:<port>/<db>?key1=value1&key2=value2
```

假设数据库运行在本机`localhost`，端口使用标准的`3306`，数据库名称是`studentdb`，那么URL如下：

```text
jdbc:mysql://localhost:3306/studentdb?useSSL=false&characterEncoding=utf8
```

后面的两个参数表示不使用SSL加密，使用UTF-8作为字符编码（注意MySQL的UTF-8是`utf8`）。

```java
// JDBC连接的URL, 不同数据库有不同的格式:
String url = "jdbc:mysql://localhost:3306/studentdb?useSSL=false&characterEncoding=utf8";
String user = "root";
String password = "123456";
// 获取连接:
Connection conn = DriverManager.getConnection(url, user, password);
// 关闭连接:
conn.close();
```

`DriverManager`会自动扫描`classpath`，找到所有的JDBC驱动，然后根据传入的URL自动挑选一个合适的驱动。

因为JDBC连接是一种昂贵的资源，所以使用后要及时释放。使用`try (resource)`来自动释放JDBC连接是一个好方法。

## 查询

```java
try (Connection conn = DriverManager.getConnection(url, user, password)) {
    try (Statement stmt = conn.createStatement()) {
        try (ResultSet rs = stmt.executeQuery("SELECT xuehao, name, sex, age FROM student WHERE sex='男'")) {
            ResultSetMetaData metaData = rs.getMetaData();//返回列名
            for (int i = 1; i <= metaData.getColumnCount(); i++) {//列从1开始
                System.out.print(metaData.getColumnName(i)+"\t");
            }
            System.out.println();
            while (rs.next()) {
                long id = rs.getInt(1); // 注意：索引从1开始
                String name = rs.getString(2);
                String sex = rs.getString("sex");//使用名称访问
                int age = rs.getInt("age");
                System.out.println(id+"\t"+name+"\t"+sex+"\t"+age);
            }
        }
    }
}
```

`Statement`对象，用于执行一个查询，executeQuery传入一个SQL字符串，并提交查询返回结果。

`ResultSetMetaData`和`ResultSet`获取列时，索引从`1`开始而不是`0`。

可以封装为`List`，不建议，为了后续维护方便，还是用`JavaBean`比较好。

```java
try (Connection conn = DriverManager.getConnection(url, user, password)) {
    try (Statement stmt = conn.createStatement()) {
        try (ResultSet rs = stmt.executeQuery("SELECT xuehao, name, sex, age FROM student WHERE sex='男'")) {
            ResultSetMetaData metaData = rs.getMetaData();//返回列名
            int count = metaData.getColumnCount();
            String []columnName=new String[count+1];
            for (int i = 1; i <= count; i++) {//列从1开始
                columnName[i]=metaData.getColumnName(i);
            }
            List<LinkedHashMap<String, Object>> list=new ArrayList<>();
            while (rs.next()) {
                LinkedHashMap<String,Object> line=new LinkedHashMap<>();
                for (int i = 1; i <= count; i++) {
                    line.put(columnName[i],rs.getObject(i));
                }
                list.add(line);
            }
            for (LinkedHashMap<String, Object> line : list) {
                System.out.println(line);
            }
        }
    }
}
```

## SQL注入

使用`Statement`拼字符串非常容易引发SQL注入的问题，这是因为SQL参数往往是从方法参数传入的。假设用户登录的验证方法如下：

```java
User login(String name, String pass) {
    ...
    stmt.executeQuery("SELECT * FROM user WHERE login='" + name + "' AND pass='" + pass + "'");
    ...
}
```

其中，参数`name`和`pass`通常都是Web页面输入后由程序接收到的。

如果用户的输入是程序期待的值，就可以拼出正确的SQL。例如：name = `"bob"`，pass = `"1234"`：

```sql
SELECT * FROM user WHERE login='bob' AND pass='1234'
```

但是，如果用户的输入是一个精心构造的字符串，就可以拼出意想不到的SQL，这个SQL也是正确的，但它查询的条件不是程序设计的意图。例如：`name` = `bob' OR pass=`, `pass` = `' OR pass='`：

```sql
SELECT * FROM user WHERE login='bob' OR pass=' AND pass=' OR pass=''
```

这个SQL语句执行的时候，根本不用判断口令是否正确，这样一来，登录就形同虚设。

要避免SQL注入攻击，要对所有字符串参数进行转义，使用`PreparedStatement`可以**完全避免SQL注入**的问题，`PreparedStatement`始终使用`?`作为占位符，在设置参数值时会自动转义特殊字符，比如单引号、双引号等。这样可以确保参数值不会被误解为 SQL 代码的一部分，从而进一步增强了防御能力，还能高效利用数据库本身对查询的缓存。上述登录SQL如果用`PreparedStatement`可以改写如下：

```java
User login(String name, String pass) {
    ...
    String sql = "SELECT * FROM user WHERE login=? AND pass=?";
    PreparedStatement ps = conn.prepareStatement(sql);
    ps.setObject(1, name);//设置第一个问号为name
    ps.setObject(2, pass);
	ResultSet rs = ps.executeQuery();
    ...
}
```

所以，使用Java对数据库进行操作时，必须使用`PreparedStatement`。

## 数据类型

使用JDBC的时候，需要在Java数据类型和SQL数据类型之间进行转换。JDBC在`java.sql.Types`定义了一组常量来表示如何映射SQL数据类型，平时使用的类型通常也就以下几种：

| SQL数据类型       | Java数据类型                 |
| :---------------- | :--------------------------- |
| `BIT`, `BOOL`     | `boolean`                    |
| `INTEGER`         | `int`                        |
| `BIGINT`          | `long`                       |
| `REAL`            | `float`                      |
| `FLOAT`, `DOUBLE` | `double`                     |
| `CHAR`, `VARCHAR` | `String`                     |
| `DECIMAL`         | `BigDecimal`                 |
| `DATE`            | `java.sql.Date`, `LocalDate` |
| `TIME`            | `java.sql.Time`, `LocalTime` |

注意：只有最新的JDBC驱动才支持`LocalDate`和`LocalTime`。

## 更新

插入操作是`INSERT`，即插入一条新记录，更新与删除也是一样的。通过JDBC进行插入，本质上也是用`PreparedStatement`执行一条SQL语句，不过最后执行的不是`executeQuery()`，而是`executeUpdate()`。当成功执行`executeUpdate()`后，返回值是`int`，表示插入的记录数量。

如果数据库的表设置了自增主键，那么在执行`INSERT`语句时，并不需要指定主键，数据库会自动分配主键。若希望以不指定列名的形式插入，则可以用0作为主键值表示自增。

```java
String sql="INSERT INTO student values(?,?,?,?,?,?)";
try (PreparedStatement ps = conn.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS)) {
    ps.setObject(1,0);
    ps.setObject(2,"张四");
    ps.setObject(3,"男");
    ps.setObject(4,20);
    ps.setObject(5,"江苏南京");
    ps.setObject(6,"计算机");

    int count = ps.executeUpdate();
    System.out.println(count);
    // 获取自动生成的主键值
    ResultSet generatedKeys = ps.getGeneratedKeys();
    if (generatedKeys.next()) {
        int primaryKey = generatedKeys.getInt(1);
        System.out.println("插入的主键值为: " + primaryKey);
    }
}
```

对于使用自增主键的程序，要获取插入后的自增主键的值，可以在创建`PreparedStatement`的时候，指定一个`RETURN_GENERATED_KEYS`标志位，表示JDBC驱动必须返回插入的自增主键。

然后调用`getGeneratedKeys()`获取一个`ResultSet`对象，这个对象包含了数据库自动生成的主键的值，读取该对象的每一行来获取自增主键的值。如果一次插入多条记录，那么这个`ResultSet`对象就会有多行返回值。如果插入时有多列自增，那么`ResultSet`对象的每一行都会对应多个自增值（自增列不一定必须是主键）。

## 事务

数据库事务（Transaction）是由若干个SQL语句构成的一个操作序列，有点类似于Java的`synchronized`同步。数据库系统保证在一个事务中的所有SQL要么全部执行成功，要么全部不执行，即数据库事务具有ACID特性：

- Atomicity：原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行；
- Consistency：一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
- Isolation：隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离；
- Durability：持久性，即事务完成后，对数据库数据的修改被持久化存储。

数据库事务可以并发执行，而数据库系统从效率考虑，对事务定义了不同的隔离级别。SQL标准定义了4种隔离级别，分别对应可能出现的数据不一致的情况：

| Isolation Level  | 脏读（Dirty Read） | 不可重复读（Non Repeatable Read） | 幻读（Phantom Read） |
| :--------------- | :----------------- | :-------------------------------- | :------------------- |
| Read Uncommitted | Yes                | Yes                               | Yes                  |
| Read Committed   | -                  | Yes                               | Yes                  |
| Repeatable Read  | -                  | -                                 | Yes                  |
| Serializable     | -                  | -                                 | -                    |

**Read Uncommitted**是隔离级别最低的一种事务级别。在这种隔离级别下，一个事务会读到另一个事务更新后但未提交的数据，如果另一个事务回滚，那么当前事务读到的数据就是脏数据，这就是脏读（Dirty Read）。

在**Read Committed**隔离级别下，一个事务可能会遇到不可重复读（Non Repeatable Read）的问题。

不可重复读是指，在一个事务内，多次读同一数据，在这个事务还没有结束时，如果另一个事务恰好修改了这个数据，那么，在第一个事务中，两次读取的数据就可能不一致。

在**Repeatable Read**隔离级别下，一个事务可能会遇到幻读（Phantom Read）的问题。

幻读是指，在一个事务中，第一次查询某条记录，发现没有，但是，当试图更新这条不存在的记录时，竟然能成功，并且，再次读取同一条记录，它就神奇地出现了。

**Serializable**是最严格的隔离级别。在Serializable隔离级别下，所有事务按照次序依次执行，因此，脏读、不可重复读、幻读都不会出现。

虽然Serializable隔离级别下的事务具有最高的安全性，但是，由于事务是串行执行，所以效率会大大下降，应用程序的性能会急剧降低。如果没有特别重要的情景，一般都不会使用Serializable隔离级别。

**默认隔离级别**

如果没有指定隔离级别，数据库就会使用默认的隔离级别。在MySQL中，如果使用`InnoDB`，默认的隔离级别是Repeatable Read。

------

对应用程序来说，数据库事务非常重要，很多运行着关键任务的应用程序，都必须依赖数据库事务保证程序的结果正常。

假设小明准备给小红支付100，两人在数据库中的记录主键分别是`123`和`456`，那么用两条SQL语句操作如下：

```sql
UPDATE accounts SET balance = balance - 100 WHERE id = 123 AND balance >= 100;
UPDATE accounts SET balance = balance + 100 WHERE id = 456;
```

这两条语句必须以事务方式执行才能保证业务的正确性，因为一旦第一条SQL执行成功而第二条SQL失败的话，系统的钱就会凭空减少100，而有了事务，要么这笔转账成功；要么转账失败，双方账户的钱都不变。

要在JDBC中执行事务，本质上就是如何把多条SQL包裹在一个数据库事务中执行。

```java
Connection conn = openConnection();
try {
    // 关闭自动提交:
    conn.setAutoCommit(false);
    // 执行多条SQL语句:
    insert(); update(); delete();
    // 提交事务:
    conn.commit();
} catch (SQLException e) {
    // 回滚事务:
    conn.rollback();
} finally {
    conn.setAutoCommit(true);
    conn.close();
}
```

其中，开启事务的关键代码是`conn.setAutoCommit(false)`，表示关闭自动提交。提交事务的代码在执行完指定的若干条SQL语句后，调用`conn.commit()`。要注意事务不是总能成功，如果事务提交失败，会抛出SQL异常（也可能在执行SQL语句的时候就抛出了），此时必须捕获并调用`conn.rollback()`回滚事务。最后，在`finally`中通过`conn.setAutoCommit(true)`把`Connection`对象的状态恢复到初始值。

如果不及时提交或者回滚，当另一个事务需要对本事务中影响的行进行**更新**的时候是会被阻塞的。一直等到事务超时释放。所以一个事物要么尽快提交，要么尽快回滚。

默认情况下，获取到`Connection`连接后，总是处于“自动提交”模式，也就是每执行一条SQL都是作为事务自动执行的。只要关闭了`Connection`的`autoCommit`，那么就可以在一个事务中执行多条语句，事务以`commit()`方法结束。

如果要设定事务的隔离级别，可以使用如下代码：

```java
// 设定隔离级别为READ COMMITTED:
conn.setTransactionIsolation(Connection.TRANSACTION_READ_COMMITTED);
```

如果没有调用上述方法，那么会使用数据库的默认隔离级别。MySQL的默认隔离级别是`REPEATABLE_READ`。

## Batch

使用JDBC操作数据库的时候，经常会执行一些批量操作。

例如，一次性给会员增加可用优惠券若干，我们可以执行以下SQL代码：

```sql
INSERT INTO coupons (user_id, type, expires) VALUES (123, 'DISCOUNT', '2030-12-31');
INSERT INTO coupons (user_id, type, expires) VALUES (234, 'DISCOUNT', '2030-12-31');
INSERT INTO coupons (user_id, type, expires) VALUES (345, 'DISCOUNT', '2030-12-31');
INSERT INTO coupons (user_id, type, expires) VALUES (456, 'DISCOUNT', '2030-12-31');
...
```

实际上执行JDBC时，因为只有占位符参数不同，所以SQL实际上是一样的：

```java
for (var params : paramsList) {
    PreparedStatement ps = conn.preparedStatement("INSERT INTO coupons (user_id, type, expires) VALUES (?,?,?)");
    ps.setLong(params.get(0));
    ps.setString(params.get(1));
    ps.setString(params.get(2));
    ps.executeUpdate();
}
```

通过一个循环来执行每个`PreparedStatement`虽然可行，但是性能很低。SQL数据库对SQL语句相同，但只有参数不同的若干语句可以作为batch执行，即批量执行，这种操作有特别优化，速度远远快于循环执行每个SQL。

可以利用SQL数据库的这一特性，把同一个SQL但参数不同的若干次操作合并为一个batch执行。

```java
try (PreparedStatement ps = conn.prepareStatement("INSERT INTO student (name, sex, age, address,depart) VALUES (?, ?, ?, ?, ?)")) {
    // 对同一个PreparedStatement反复设置参数并调用addBatch():
    for (Student s : students) {
        ps.setString(1, s.name);
        ps.setString(2, s.sex);
        ps.setInt(3, s.age);
        ps.setString(4, s.address);
        ps.setString(4, s.depart);
        ps.addBatch(); // 添加到batch
    }
    // 执行batch:
    int[] ns = ps.executeBatch();
    for (int n : ns) {
        System.out.println(n + " inserted."); // batch中每个SQL执行的结果数量
    }
}
```

执行batch和执行一个SQL不同点在于，需要对同一个`PreparedStatement`反复设置参数并调用`addBatch()`，这样就相当于给一个SQL加上了多组参数，相当于变成了“多行”SQL。

第二个不同点是调用的不是`executeUpdate()`，而是`executeBatch()`，因为设置了多组参数，相应地，返回结果也是多个`int`值，因此返回类型是`int[]`，循环`int[]`数组即可获取每组参数执行后影响的结果数量。

另外MySQL批处理默认是关闭的，如果需要开启，在`url`上添加 ：

```text
rewriteBatchedStatements=true
```

## 连接池

在执行JDBC的增删改查的操作时，如果每一次操作都来一次打开连接，操作，关闭连接，那么创建和销毁JDBC连接的开销就太大了。为了避免频繁地创建和销毁JDBC连接，可以通过连接池（Connection Pool）复用已经创建好的连接。

JDBC连接池有一个标准的接口`javax.sql.DataSource`，注意这个类位于Java标准库中，但仅仅是接口。要使用JDBC连接池，必须选择一个JDBC连接池的实现。常用的JDBC连接池有`HikariCP`、`C3P0`、`BoneCP`、`Druid`。目前使用最广泛的是`HikariCP`。

```xml
<!-- https://mvnrepository.com/artifact/com.zaxxer/HikariCP -->
<dependency>
    <groupId>com.zaxxer</groupId>
    <artifactId>HikariCP</artifactId>
    <version>5.1.0</version>
</dependency>
```

```java
HikariConfig config = new HikariConfig();
config.setJdbcUrl("jdbc:mysql://localhost:3306/studentdb?useSSL=false&characterEncoding=utf8");
config.setUsername("root");
config.setPassword("123456");
config.addDataSourceProperty("connectionTimeout", "1000"); // 连接超时：1秒
config.addDataSourceProperty("idleTimeout", "60000"); // 空闲超时：60秒
config.addDataSourceProperty("maximumPoolSize", "10"); // 最大连接数：10
DataSource ds = new HikariDataSource(config);
```

`DataSource`实例就是连接池，创建`DataSource`也是一个非常昂贵的操作，所以通常`DataSource`实例总是作为一个全局变量存储，并贯穿整个应用程序的生命周期。

有了连接池以后获取`Connection`时，把`DriverManage.getConnection()`改为`ds.getConnection()`即可。

通过连接池获取连接时，并不需要指定JDBC的相关URL、用户名、口令等信息，因为这些信息已经存储在连接池内部了（创建`HikariDataSource`时传入的`HikariConfig`持有这些信息）。一开始，连接池内部并没有连接，所以，第一次调用`ds.getConnection()`，会迫使连接池内部先创建一个`Connection`，再返回给客户端使用。当我们调用`conn.close()`方法时（`在try(resource){...}`结束处），不是真正“关闭”连接，而是释放到连接池中，以便下次获取连接时能直接返回。

连接池内部维护了若干个`Connection`实例，如果调用`ds.getConnection()`，就选择一个空闲连接，并标记它为“正在使用”然后返回，如果对`Connection`调用`close()`，那么就把连接再次标记为“空闲”从而等待下次调用。这样一来，就通过连接池维护了少量连接，但可以频繁地执行大量的SQL语句。

通常连接池提供了大量的参数可以配置，例如，维护的最小、最大活动连接数，指定一个连接在空闲一段时间后自动关闭等，需要根据应用程序的负载合理地配置这些参数。大多数连接池都提供了详细的实时状态以便进行监控。





# GUI

`JFrame`  **构造方法**  

| 方法                                             | 说明                                                         |
| ------------------------------------------------ | ------------------------------------------------------------ |
| `JFrame()`                                       | 构造一个初始时不可见的新窗体。                               |
| `JFrame(GraphicsConfiguration gc)`               | 以屏幕设备的指定 `GraphicsConfiguration` 和空白标题创建一个 `Frame`。 |
| `JFrame(String title)`                           | 创建一个新的、初始不可见的、具有指定标题的 `Frame`。         |
| `JFrame(String title, GraphicsConfiguration gc)` | 创建一个具有指定标题和指定屏幕设备的 `GraphicsConfiguration` 的 `JFrame`。 |

**常用方法**  

| 方法                                      | 说明                                   |
| ----------------------------------------- | -------------------------------------- |
| `add()`                                   | 将组件添加到窗口                       |
| `is/setVisible()`                         | 获取/设置窗体的可视状态。              |
| `get/setTitle()`                          | 获取/设置窗体的标题。                  |
| `get/setState()`                          | 获取/设置窗体的的最小化,最大化等状态。 |
| `get/setLocation()`                       | 获取/设置窗体在屏幕上应当出现的位置。  |
| `get/setSize()`                           | 获取/设置窗体的大小。                  |
| `setDefaultCloseOperation(int operation)` | 设置单击窗体上的关闭按钮时的默认操作。 |
| `getContentPane()`                        | 获取窗体的内容面板                     |

`setDefaultCloseOperation`  

`public void setDefaultCloseOperation(int operation)`  
设置用户在此窗体上发起"`close`"时默认执行的操作。必须指定以下选项之一：  

值依次为`0-3`  

`DO_NOTHING_ON_CLOSE`(在 WindowConstants 中定义)：不执行任何操作;要求程序在已注册的 `WindowListener` 对象的 `windowClosing` 方法中处理该操作。  

`HIDE_ON_CLOSE`(在 `WindowConstants` 中定义)：调用任意已注册的 `WindowListener` 对象后自动隐藏该窗体。  

`DISPOSE_ON_CLOSE`(在 `WindowConstants` 中定义)：调用任意已注册 `WindowListener` 的对象后自动隐藏并释放该窗体。  

`EXIT_ON_CLOSE`(在 `JFrame` 中定义)：使用 `System exit` 方法退出应用程序。仅在应用程序中使用。  

默认情况下,该值被设置为 `HIDE_ON_CLOSE`。更改此属性的值将导致激发属性更改事件,其属性名称为 "`defaultCloseOperation`"。  

注：当 Java 虚拟机 (VM) 中最后一个可显示窗口被释放后,虚拟机**可能**会终止。  
`frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);`  

# JVM

## 对象的生命周期

在Java中，对象在堆内存中的生命周期和垃圾回收（GC）过程涉及多个阶段，通常遵循以下路径：对象创建、晋升到老年代、最终被垃圾回收。

**对象创建**

当在Java程序中使用`new`关键字创建一个对象时，该对象首先被分配在堆内存中的新生代（Young Generation）的Eden区：

```java
MyObject obj = new MyObject();
```

**新生代（Young Generation）**

新生代通常分为三个区域：Eden区和两个Survivor区（S0和S1）。

- **Eden区**：大部分新对象最初在这里分配。
- **Survivor区**：当Eden区满时，进行Minor GC（轻量级垃圾回收），存活的对象会被移动到Survivor区。Survivor区分为两个：S0和S1，轮流使用。

**晋升到老年代（Old Generation）**

对象在新生代中存活多次Minor GC后，会被晋升（Promote）到老年代。这通常通过以下过程实现：

- **Minor GC**：当Eden区满时触发，存活的对象会被移动到Survivor区。如果对象在多个GC周期中依然存活（通常由对象的年龄计数决定），它们最终会被晋升到老年代。
- **老年代**：存活时间较长或较大的对象会被移动到老年代。老年代空间较大，存储持久化对象。

**老年代（Old Generation）**

在老年代中，对象可以存活更长时间。然而，当老年代也满了时，会触发Major GC或Full GC，这种GC比Minor GC更耗时：

- **Major GC / Full GC**：清理老年代和新生代的垃圾回收，回收未被引用的对象。通常由CMS（Concurrent Mark-Sweep）或G1（Garbage First）垃圾收集器完成。

**垃圾回收（Garbage Collection）**

对象生命周期的最终阶段是垃圾回收。对象不再被引用时，它们会被标记为可回收，并在GC过程中被清除以释放内存：

- **标记-清除（Mark-Sweep）**：标记所有不可达的对象，然后清除它们。
- **标记-整理（Mark-Compact）**：标记阶段后，将存活的对象压缩到堆的一端，清理掉未使用的空间。
- **复制（Copying）**：将存活对象复制到新的内存区域，通常用于新生代的Minor GC。

**对象生命周期示例**

1. **对象创建**：新对象`obj`在Eden区分配。
2. **Minor GC**：Eden区满，进行Minor GC，`obj`被移动到Survivor区。
3. **晋升到老年代**：如果`obj`在多次Minor GC后依然存活，它将被晋升到老年代。
4. **Major GC**：当老年代满时，进行Major GC或Full GC，`obj`被回收。

## 各区域的数据

- 堆：对象实例、String常量池、基本类型常量池、静态变量。
- 方法区（元空间）：类信息、类常量池、运行时常量池。
- 虚拟机栈：临时变量（方法内的变量）

方法区是《Java 虚拟机规范》规定的一个抽象的概念。永久代和元空间是方法区的两种实现方式。

**JDK8之前**：用永久代作为方法区的实现，占用JVM的空间，通过Full GC进行垃圾回收（回收效率很低）。

**JDK8开始**：用元空间作为方法区的实现，使用本地内存，不占用JVM的空间。元空间有自己的垃圾回收机制。

**JDK8为什么要调整方法区的位置？**

永久代通过Full GC进行垃圾回收，回收效率很低。

永久代有JVM 设置的固定大小上限，无法进行调整。而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。元空间里面存放的是类的元数据，这样加载的元数据就不由 MaxPermSize 控制了, 而由系统的实际可用空间控制，这样能加载的类就更多了。

元空间溢出时会得到如下错误：java.lang.OutOfMemoryError: MetaSpace

相关参数：

1. -XX：MaxMetaspaceSize。最大元空间大小，默认值为 unlimited，表示只受系统内存的限制。
2. -XX：MetaspaceSize 元空间的初始大小，如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。

## 永久代和元空间

永久代（Permanent Generation）和元空间（Metaspace）是 Java 虚拟机（JVM）内存管理中的两个概念，用于存储与类和方法相关的元数据。它们在不同版本的 JVM 中有不同的实现和管理方式。

**永久代（Permanent Generation）**

**永久代**是 JDK 8 之前的 JVM 内存模型的一部分，用于存储类的元数据、方法、常量池和类的静态变量等信息。永久代的特点包括：

- **固定大小**：永久代的大小在 JVM 启动时通过参数设置，不能动态调整。
- **GC 影响**：永久代会参与垃圾回收，特别是 Full GC。如果永久代空间不足，可能会触发 Full GC，从而影响应用程序性能。
- **设置参数**：
  - `-XX:PermSize=<size>`：设置初始永久代大小。
  - `-XX:MaxPermSize=<size>`：设置最大永久代大小。

**元空间（Metaspace）**

**元空间**是从 JDK 8 开始引入的，用来取代永久代的新内存区域。元空间的改进在于其存储机制和内存管理方式：

- **动态调整**：元空间使用本地内存（Native Memory），其大小可以根据需要动态调整，不再受到固定大小的限制。
- **减少 OOM 发生率**：由于元空间使用本地内存，可以有效减少因为类加载过多导致的 OutOfMemoryError (OOM) 问题。
- **设置参数**：
  - `-XX:MetaspaceSize=<size>`：设置初始元空间大小。
  - `-XX:MaxMetaspaceSize=<size>`：设置最大元空间大小（如果不设置，默认情况下元空间大小是可以增长到可用系统内存的上限）。
  - `-XX:MinMetaspaceFreeRatio=<percentage>`：设置 GC 后元空间的最小空闲比例。
  - `-XX:MaxMetaspaceFreeRatio=<percentage>`：设置 GC 后元空间的最大空闲比例。

**永久代和元空间的区别**

1. **内存区域**：
   - 永久代：位于 Java 堆内存中。
   - 元空间：位于本地内存（Native Memory）中。

2. **内存管理**：
   - 永久代：大小固定，容易导致 OutOfMemoryError。
   - 元空间：动态调整大小，更加灵活，减少 OutOfMemoryError 发生率。

3. **垃圾回收**：
   - 永久代：需要参与垃圾回收，特别是 Full GC。
   - 元空间：减少了 Full GC 的频率，提高了垃圾回收的效率。



如果还在使用 JDK 7 或更早版本，建议升级到 JDK 8 或更高版本，以利用元空间带来的内存管理优势。升级后，可以删除或调整与永久代相关的 JVM 参数，并改用与元空间相关的参数。

```bash
# 示例：JDK 7 的 JVM 参数
java -XX:PermSize=256m -XX:MaxPermSize=512m -jar myapp.jar

# 示例：JDK 8 及以上的 JVM 参数
java -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m -jar myapp.jar
```

通过合理配置和使用元空间，可以更好地管理类元数据的内存，提高应用程序的性能和稳定性。



## 内存模型

Java内存模型（Java Memory Model，简称JMM）是Java虚拟机规范中的一部分，用于定义Java程序在多线程环境下的内存访问规则。JMM规定了变量的读取和写入如何在不同线程之间进行交互，确保程序在不同硬件和操作系统上的执行具有一致性。

**基本概念**

- **主内存（Main Memory）**: 所有的实例变量（非局部变量）都存储在主内存中。主内存是多个线程共享的内存区域。
- **工作内存（Working Memory）**: 每个线程都有自己的工作内存，也叫本地内存。线程的工作内存保存了主内存中变量的副本，线程对变量的所有操作（如读取、赋值）都在工作内存中进行，而不是直接在主内存中进行。

**工作流程**

- **读取和加载**: 线程从主内存读取变量值，并将其存放到工作内存中。
- **使用和赋值**: 线程在工作内存中使用或更新变量值。
- **存储和写入**: 线程将更新后的变量值从工作内存写回到主内存。

**JMM的关键原则**

JMM的设计主要解决三个问题：**原子性**、**可见性**和**有序性**。

原子性（Atomicity）

- **原子性**是指一个操作是不可分割的，执行过程中不会被其他线程干扰。
- 在Java中，简单的读取和赋值操作是原子性的，比如读取和写入`int`类型的变量。但是对于复合操作，如`i++`，并不是原子性的，因为它包括读取、增值和写入三个步骤。

可见性（Visibility）

- **可见性**是指一个线程对共享变量的修改可以及时被其他线程看到。
- 在JMM中，线程A对变量的修改在写入到主内存后，线程B读取时才能看到。为了保证可见性，可以使用`volatile`关键字、`synchronized`块或锁机制。

有序性（Ordering）

- **有序性**是指程序代码的执行顺序在多线程环境下的一致性。
- JMM允许编译器和处理器在不改变单线程语义的前提下对指令进行重排序。为了保证多线程环境下的正确执行，可以使用`volatile`、`synchronized`或锁来禁止重排序。

.**happens-before原则**

JMM通过**happens-before**原则来定义操作之间的顺序性和可见性。
- **程序次序规则**: 在一个线程内，按照代码顺序，前面的操作happens-before后面的操作。
- **锁定规则**: 对一个锁的解锁happens-before对这个锁的加锁。
- **volatile变量规则**: 对一个`volatile`变量的写操作happens-before对这个`volatile`变量的读操作。
- **线程启动规则**: `Thread.start()`happens-before线程内的所有操作。
- **线程终止规则**: 线程内的所有操作happens-before对`Thread.join()`的返回。

**内存屏障（Memory Barriers）**

JMM通过插入**内存屏障**（Memory Barriers，也称为Memory Fences）来防止重排序和确保内存可见性。内存屏障可以分为：
- **Load Barrier**: 在读取操作之前，阻止重排序。
- **Store Barrier**: 在写入操作之后，阻止重排序。

**常用关键字**

- **volatile**: 保证变量的可见性和有序性，但不保证原子性。使用`volatile`修饰的变量，在多线程访问时，会禁止指令重排序，并强制将更新后的值写回主内存，使得其他线程可以及时看到最新值。
- **synchronized**: 保证代码块的原子性、可见性和有序性。`synchronized`会确保线程在进入代码块之前获得锁，并在退出代码块后释放锁，保证共享变量的操作是原子性的，并且锁释放前的所有修改对其他线程可见。



Java内存模型（JMM）为开发者提供了一套清晰的规则，确保在多线程环境下，代码的执行顺序和内存访问的一致性。理解JMM有助于编写正确且高效的并发程序，避免常见的并发问题，如竞态条件、内存可见性问题和指令重排序带来的不确定性。

## 类加载过程

加载=> 链接（验证+准备+解析）=> 初始化=> 使用=> 卸载

1. 加载（将硬盘上的Java二进制文件（class文件）转为内存中的Class对象）

   1. 通过一个类的全限定名获取定义此类的二进制字节流。
   2. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
   3. 在内存（不一定在堆中，HotSpot是在方法区）中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。

2. 链接（给静态变量赋初始值，符号引用替换成直接引用）

   1. **验证**：检查载入的class文件数据的正确性

   2. 准备：给类变量（静态变量）分配内存（方法区）并设置为零值（0、false、null等）。

      例外：static final类型的String或基本类型，直接赋值为最终值，如：static final int a = 12; 在准备阶段就将a赋值为12。

   3. 解析（可选）：将常量池内的符号引用替换成直接引用。

      符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用 ，那引用的目标必定已经在内存中存在。

3. 初始化（初始化类变量（静态变量）、执行静态语句块）

   执行类变量（静态变量）的赋值动作和静态语句块（按定义的顺序从上往下执行）。优先级：静态、父类、子类

   注意：初始化是操作类变量（也就是静态变量），不是对象的变量。

4. 使用（以new一个对象为例）

   1. 若是第一次创建 Dog 对象（对象所属的类没有加载到内存中）则先执行上面的初始化操作。
   2. 在堆上为 Dog 对象（包括实例变量）分配空间，所有属性都设成默认值(数字为 0，字符为 null，布尔为 false，引用被设成 null）
   3. 初始化实例：给实例变量赋值、执行初始化语句块
   4. 执行构造函数检查是否有父类，如果有父类会先调用父类的构造函数
   5. 执行本类的构造函数。



## 调优

Java 虚拟机（JVM）提供了许多参数来调整其行为和性能。以下是一些常见的 JVM 参数及其用途：

**内存设置**

- `-Xms<size>`：设置初始堆大小。例如：`-Xms512m`
- `-Xmx<size>`：设置最大堆大小。例如：`-Xmx1024m`
- `-Xmn<size>`：设置年轻代大小。例如：`-Xmn256m`
- `-XX:PermSize=<size>`：设置初始永久代大小（对于 JDK 8 之前的版本）。
- `-XX:MaxPermSize=<size>`：设置最大永久代大小（对于 JDK 8 之前的版本）。
- `-XX:MetaspaceSize=<size>`：设置初始元空间大小（对于 JDK 8 及以上版本）。
- `-XX:MaxMetaspaceSize=<size>`：设置最大元空间大小（对于 JDK 8 及以上版本）。

**垃圾回收（GC）设置**

- `-XX:+UseSerialGC`：使用串行垃圾收集器。
- `-XX:+UseParallelGC`：使用并行垃圾收集器（默认的垃圾收集器之一）。
- `-XX:+UseConcMarkSweepGC`：使用并发标记-清除垃圾收集器。
- `-XX:+UseG1GC`：使用 G1 垃圾收集器。
- `-XX:NewRatio=<ratio>`：设置新生代与老年代的比例。
- `-XX:SurvivorRatio=<ratio>`：设置 Eden 区与 Survivor 区的比例。
- `-XX:MaxTenuringThreshold=<threshold>`：设置对象在新生代的最大年龄。
- `-XX:+PrintGCDetails`：打印 GC 详细信息。
- `-XX:+PrintGCDateStamps`：在 GC 日志中打印时间戳。
- `-Xloggc:<file>`：将 GC 日志写入文件。

**性能调优**

- `-XX:+UseCompressedOops`：在 64 位 JVM 中使用压缩指针。
- `-XX:+AggressiveOpts`：使用最新的性能优化。
- `-XX:+TieredCompilation`：启用分层编译。
- `-XX:ParallelGCThreads=<threads>`：设置并行 GC 的线程数。
- `-XX:ConcGCThreads=<threads>`：设置并发 GC 的线程数。

**调试和诊断**

- `-XX:+HeapDumpOnOutOfMemoryError`：在出现内存溢出时生成堆转储。
- `-XX:HeapDumpPath=<file>`：指定堆转储文件路径。
- `-XX:+PrintClassHistogram`：打印类的直方图。
- `-XX:+PrintConcurrentLocks`：打印并发锁的信息。
- `-XX:+TraceClassLoading`：跟踪类加载。
- `-XX:+TraceClassUnloading`：跟踪类卸载。

**类加载和编译**

- `-Xbootclasspath:<path>`：设置引导类加载器的类路径。
- `-XX:CompileThreshold=<invocations>`：设置方法编译的调用阈值。
- `-XX:+PrintCompilation`：打印编译信息。
- `-XX:+PrintInlining`：打印内联信息。

**其他常用参数**

- `-D<name>=<value>`：设置系统属性。例如：`-Dfile.encoding=UTF-8`
- `-verbose:gc`：启用 GC 日志。
- `-verbose:class`：启用类加载日志。
- `-verbose:jni`：启用 JNI 调用日志。
- `-server`：启用服务器模式（针对高性能应用）。

这些参数可以在启动 Java 应用程序时通过命令行传递，例如：

```bash
java -Xms512m -Xmx1024m -XX:+UseG1GC -XX:+PrintGCDetails -jar myapp.jar
```

具体的参数和配置需要根据应用程序的需求和运行环境进行调整和优化。



# MYSQL

## 锁

在MySQL中，锁（Locks）是用于控制并发访问数据库对象（如表和行）的机制。锁可以防止多个事务同时修改相同的数据，从而避免数据不一致或损坏。MySQL提供了多种锁定机制，以满足不同的并发控制需求。以下是MySQL中常见的锁类型：

1. 表锁（Table Locks）

表锁是针对整个表的锁定机制。MySQL使用表锁来确保对表的操作（如INSERT、UPDATE、DELETE等）的一致性。

- **读锁（READ LOCK）**：允许多个事务同时读取表，但不允许任何事务修改表。
  
  ```sql
  LOCK TABLES table_name READ;
  ```
  
- **写锁（WRITE LOCK）**：只允许一个事务访问表，其他事务既不能读取也不能修改表。
  ```sql
  LOCK TABLES table_name WRITE;
  ```

2. 行锁（Row Locks）

行锁是针对特定行的锁定机制。InnoDB存储引擎支持行级锁定，这样可以在同一张表中允许多个事务同时修改不同的行，从而提高并发性。

- **共享锁（S锁，Shared Lock）**：允许多个事务读取同一行，但不允许修改。
  ```sql
  SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE;
  ```

- **排他锁（X锁，Exclusive Lock）**：不允许其他事务读取或修改锁定的行。
  ```sql
  SELECT * FROM table_name WHERE ... FOR UPDATE;
  ```

3. 意向锁（Intent Locks）

意向锁是InnoDB自动添加的一种锁，用于表明某个事务计划对某些行加锁。这种锁的存在使得MySQL能够更高效地进行锁定检查和锁定升级。

- **意向共享锁（IS锁，Intent Shared Lock）**：表明事务计划对某些行加共享锁。
- **意向排他锁（IX锁，Intent Exclusive Lock）**：表明事务计划对某些行加排他锁。

4. 间隙锁（Gap Locks）

间隙锁用于防止幻读（Phantom Read），它会锁定索引记录之间的“间隙”，以确保其他事务无法在这些间隙中插入新记录。

5. 临键锁（Next-Key Locks）

临键锁是行锁和间隙锁的组合，用于防止其他事务对锁定行及其周围的间隙进行插入操作。临键锁用于防止幻读问题。

6. 自增锁（AUTO-INC Locks）

自增锁用于确保多个事务同时插入带有AUTO_INCREMENT列的表时，生成的自增值是唯一的。

7. 全局锁（Global Locks）

全局锁用于整个数据库实例的锁定，可以将数据库设置为只读模式，以进行备份等操作。
```sql
FLUSH TABLES WITH READ LOCK;
```

**锁的使用示例**

**表锁示例：**
```sql
LOCK TABLES employees WRITE;
-- Perform write operations on the employees table
UNLOCK TABLES;
```

**行锁示例：**
```sql
START TRANSACTION;
SELECT * FROM employees WHERE id = 1 FOR UPDATE;
-- Perform operations on the locked row
COMMIT;
```

**查看锁信息**

可以使用以下命令查看当前锁的信息：

```sql
SHOW ENGINE INNODB STATUS;
```

或查询`information_schema`表：

```sql
SELECT * FROM information_schema.innodb_locks;
SELECT * FROM information_schema.innodb_lock_waits;
```

了解和合理使用锁机制是确保数据库高效、安全并发访问的关键。

## 区域锁

MySQL中的区域锁（也称为间隙锁，Gap Lock）是一种用于InnoDB存储引擎的锁机制。其主要作用是防止幻读现象和保持一致性。区域锁是在使用范围条件（Range Condition）进行查询时，对索引记录之间的空隙（Gap）加锁，以确保并发事务中数据的一致性。

**区域锁的主要作用**

1. **防止幻读**：幻读是指在一个事务中，两次相同的查询却得到不同的结果。区域锁通过锁定索引记录之间的空隙，防止其他事务在这些空隙中插入新的记录，从而避免幻读现象的发生。
   
2. **保持一致性**：区域锁确保在一个事务中，数据的读取和写入是基于一致性的视图，不会因为其他事务的插入或删除操作而导致数据不一致。

**区域锁的工作机制**

区域锁主要在以下两种情况下被使用：

1. **在范围查询时加锁**：当使用范围查询条件（如`SELECT * FROM my_table WHERE col BETWEEN 10 AND 20 FOR UPDATE`）时，InnoDB会锁定满足条件的记录和这些记录之间的空隙，以防止其他事务在这些空隙中插入新记录。

2. **在唯一索引上进行插入操作时加锁**：当对唯一索引列进行插入操作时，如果存在唯一性约束，InnoDB会锁定可能冲突的索引记录之间的空隙，以确保插入操作的唯一性。

**区域锁的示例**

以下是一个使用区域锁的示例：

```sql
-- 创建示例表
CREATE TABLE my_table (
    id INT PRIMARY KEY,
    col INT
);

-- 插入一些示例数据
INSERT INTO my_table (id, col) VALUES (1, 10), (2, 20), (3, 30);

-- 开始事务1
START TRANSACTION;
-- 对满足条件的记录及其间隙加锁
SELECT * FROM my_table WHERE col BETWEEN 15 AND 25 FOR UPDATE;

-- 开始事务2
START TRANSACTION;
-- 尝试在间隙中插入新记录（会被阻塞）
INSERT INTO my_table (id, col) VALUES (4, 17);

-- 提交事务1
COMMIT;

-- 事务2继续执行，插入操作成功
COMMIT;
```

在这个示例中，事务1通过范围查询条件对满足条件的记录及其间隙加锁，防止事务2在这些间隙中插入新记录。只有当事务1提交后，事务2才能继续执行插入操作。

**区域锁的注意事项**

1. **性能影响**：区域锁在防止幻读和保持一致性方面起到了重要作用，但也可能会影响性能，特别是在高并发环境中。锁定空隙会导致更多的锁竞争和潜在的死锁情况。

2. **锁定范围**：区域锁只适用于InnoDB存储引擎，并且仅在可重复读（REPEATABLE READ）隔离级别下生效。在读提交（READ COMMITTED）隔离级别下，InnoDB不会使用区域锁。

MySQL中的区域锁（Gap Lock）是InnoDB存储引擎中的一种重要锁机制，用于防止幻读现象和保持数据一致性。通过锁定索引记录之间的空隙，区域锁确保了并发事务中的数据一致性和可靠性。然而，区域锁的使用也可能带来性能影响，因此在设计和优化数据库应用时，需要权衡锁机制的使用和系统性能之间的关系。

## 索引

在MySQL中，存储索引的两种主要类型分别是：

1. **聚集索引（Clustered Index）**
2. **非聚集索引（Non-Clustered Index）**

### 聚集索引（Clustered Index）

聚集索引是表中数据行的实际顺序与索引顺序一致的索引类型。每个表只能有一个聚集索引，因为表中的数据行只能按一种顺序存储。

- **特点**：
  - 数据行按照聚集索引的键值排序存储。
  - 通常会自动地将主键作为聚集索引。
  - 查询效率高，特别是在范围查询和排序查询中。
  - 插入和更新操作可能较慢，因为需要保持数据的有序性。

- **示例**：
  ```sql
  CREATE TABLE example (
      id INT PRIMARY KEY,
      name VARCHAR(50)
  );
  ```

### 非聚集索引（Non-Clustered Index）

非聚集索引是索引的键值和数据行的物理存储顺序无关的索引类型。一个表可以有多个非聚集索引。

- **特点**：
  - 非聚集索引存储的是键值及其对应的行指针。
  - 查询操作中，MySQL会通过非聚集索引查找到行指针，然后根据行指针访问实际的数据行。
  - 适合频繁的查询操作，但由于需要访问实际的数据行，查询效率可能不如聚集索引。
  - 适用于多种查询条件，不限于主键。

- **示例**：
  ```sql
  CREATE TABLE example (
      id INT PRIMARY KEY,
      name VARCHAR(50),
      age INT,
      INDEX (name)
  );
  ```

在MySQL中，聚集索引和非聚集索引是两种主要的存储索引类型。聚集索引用于将表中数据行按索引键值的顺序存储，而非聚集索引则存储键值和行指针以便快速查询。了解并正确使用这两种索引可以显著提高数据库查询性能。

### 索引失效的情况

在MySQL中，索引是用来提高查询性能的重要工具。然而，在某些情况下，索引可能会失效，导致查询性能下降。以下是一些常见的索引失效情况：

1. 索引字段上使用函数或表达式

如果在查询中对索引字段使用了函数或表达式，索引会失效，因为MySQL无法利用索引来优化查询。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE LOWER(indexed_column) = 'value';
```

2. 隐式数据类型转换

如果查询中的条件涉及隐式数据类型转换，索引也会失效。例如，索引字段是字符串类型，但查询条件是数值类型。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE indexed_column = 123;
```

3. 使用不等于或不包含（<>、NOT IN、NOT LIKE）

使用这些操作符，索引通常会失效，因为MySQL需要扫描更多的数据行来确定结果集。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE indexed_column <> 'value';
```

4. 以通配符开头的LIKE查询

如果LIKE查询的模式以通配符（%）开头，索引会失效，因为MySQL无法预测匹配的起始位置。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE indexed_column LIKE '%value';
```

5. 不使用前缀匹配的复合索引

对于复合索引，如果查询条件中没有包含索引的前缀列，索引会失效。

```sql
-- 假设有一个复合索引 (column1, column2)
-- 索引失效的例子
SELECT * FROM table WHERE column2 = 'value';
```

6. OR 条件中某些条件未使用索引

如果查询中的OR条件部分列使用了索引，但另一部分没有使用索引，MySQL无法有效地利用索引。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE indexed_column = 'value1' OR non_indexed_column = 'value2';
```

7. 范围条件后面的列

在复合索引中，如果使用了范围条件（如 >, <, BETWEEN），则范围条件后面的列索引会失效。

```sql
-- 假设有一个复合索引 (column1, column2)
-- 索引失效的例子
SELECT * FROM table WHERE column1 > 10 AND column2 = 'value';
```

8. NULL 值查询

如果在查询条件中对索引字段进行了 IS NULL 或 IS NOT NULL 的判断，索引可能失效。

```sql
-- 索引失效的例子
SELECT * FROM table WHERE indexed_column IS NULL;
```

9. 表太小或数据分布不均

如果表非常小，MySQL可能会选择全表扫描而不是使用索引。另外，如果数据分布非常不均匀，MySQL可能也会选择全表扫描。

```sql
-- 索引失效的例子（小表）
SELECT * FROM small_table WHERE indexed_column = 'value';
```

10. 更新频繁的表

在高频率更新的表上，MySQL可能会临时选择全表扫描以避免频繁的索引更新带来的开销。

11. 使用LIMIT子句不当

有些情况下，如果LIMIT子句的偏移量非常大，索引可能会失效。

```sql
-- 索引失效的例子（大偏移量）
SELECT * FROM table ORDER BY indexed_column LIMIT 1000000, 10;
```

理解这些索引失效的情况有助于在设计和优化数据库查询时，避免常见的性能陷阱。

### 强制走索引

在MySQL中，有几种方法可以强制查询使用索引。以下是一些常用的方法：

1. 使用 `FORCE INDEX` 提示

`FORCE INDEX` 提示可以指定查询必须使用的索引。如果不使用指定的索引，查询将失败。

```sql
SELECT * FROM table_name FORCE INDEX (index_name) WHERE column = 'value';
```

2. 使用 `USE INDEX` 提示

`USE INDEX` 提示建议 MySQL 优先考虑使用指定的索引，但如果 MySQL 认为不使用索引会更高效，它可能仍会选择不使用索引。

```sql
SELECT * FROM table_name USE INDEX (index_name) WHERE column = 'value';
```

3. 使用 `IGNORE INDEX` 提示

`IGNORE INDEX` 提示告诉 MySQL 忽略指定的索引。这在您想要排除某些索引的情况下很有用。

```sql
SELECT * FROM table_name IGNORE INDEX (index_name) WHERE column = 'value';
```

4. 覆盖索引（Covering Index）

覆盖索引指的是查询所需的所有列都在索引中，这样 MySQL 可以直接从索引中返回结果，而无需访问数据表。

```sql
-- 假设有一个复合索引 (column1, column2)
SELECT column1, column2 FROM table_name WHERE column1 = 'value';
```

5. 使用 `EXPLAIN` 语句查看查询计划

在执行查询之前，可以使用 `EXPLAIN` 语句查看查询计划，确保索引正在使用。

```sql
EXPLAIN SELECT * FROM table_name WHERE column = 'value';
```

6. 确保查询条件匹配索引

确保查询条件匹配索引的列，避免使用函数、表达式或隐式类型转换。

```sql
-- 直接匹配索引列
SELECT * FROM table_name WHERE indexed_column = 'value';
```

示例：

假设有一个表 `employees`，包含以下索引：

```sql
CREATE INDEX idx_last_name ON employees (last_name);
```

我们希望强制查询使用该索引，可以使用 `FORCE INDEX` 提示：

```sql
SELECT * FROM employees FORCE INDEX (idx_last_name) WHERE last_name = 'Smith';
```

在某些情况下，您可能需要使用复合索引。例如，假设有一个复合索引：

```sql
CREATE INDEX idx_full_name ON employees (first_name, last_name);
```

为了强制查询使用该复合索引，可以使用：

```sql
SELECT * FROM employees FORCE INDEX (idx_full_name) WHERE first_name = 'John' AND last_name = 'Smith';
```

通过使用这些方法，可以更好地控制查询执行计划，确保查询在最优的情况下执行。

### 索引的优缺点

**索引优点**

索引优点就是提高了查询性能，主要是以下几个方面

1. 索引大大减少了服务器需要扫描的数据量。
2. 索引可以帮助服务器避免排序和临时表。
3. 索引可以将随机I/O 变为顺序I/O

**索引缺点**

**降低了数据写入的效率。**

原因：当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护。

**索引增加了查询优化器的选择时间。**

查询优化器在对一条sql语句进行分析时，会结合一系列的分析计算出一条最优的查询sql。

添加了索引之后，相当于是在原来的基础上，添加了对索引因素的分析，若在很多字段上创建了索引，会增加这个选择的时间。

**索引占物理空间。**

除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。

**创建索引的原则**

| 索引原则                                     | 说明/示例                                                    |
| -------------------------------------------- | ------------------------------------------------------------ |
| 对查询频率高的字段创建索引                   | 查询频率高的字段有：作为查询条件的字段（where子句中的列）、连接子句中指定的列 |
| 为经常需要排序、分组和联合操作的字段建立索引 | 经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。     如果为其建立索引，可以有效地避免排序操作。 |
| 尽量使用唯一索引                             | 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。唯一值少的列上不适合建立索引或者建立索引效率低，因为创建索引会对那一列做自动的排序。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。若使用姓名的话，可能存在同名现象，从而降低查询速度。     主键索引和唯一键索引，在查询中使用是效率最高的。 |
| 使用短索引                                   | 如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。 |
| 使用前缀来索引                               | 如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。 |
| 索引的数目不要太多                           | 1. 每创建一个索引都会占用相应的物理空间； 2. 过多的索引会导致insert、update、delete语句的执行效率降低；     在修改表的内容时，索引必须进行更新，有时可能需要重构，因此，索引越多，所花的时间越长。若一个索引很少利用或从不使用，那么会不必要地减缓表的修改速度。此外，MySQL 在生成一个执行计划时，要考虑各个索引，这也要费时间。创建多余的索引给查询优化带来了更多的工作。索引太多，也可能会使MySQL 选择不到所要使用的最好索引。只保持所需的索引有利于查询优化。如果想给已索引的表增加索引，应该考虑所要增加的索引是否是现有多列索引的最左索引。如果是，则就不要费力去增加这个索引了，因为已经有了。 |
| 避免索引失效                                 |                                                              |

**不推荐使用索引的情况**

| **情况**                                                   | **说明**                                                     |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| 查询不频繁的字段                                           | 既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 |
| 数据唯一性差（一个字段的取值只有几种时）的字段不要使用索引 | 比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。 |
| 修改频率远远大于查询频率                                   | 比如login count（登录次数），频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。     修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 |

## 存储引擎-MyISAM和InnoDB的区别

**InnoDB占优势的项**

| **项**       | **InnoDB**                                                   | **MyISAM**        |
| ------------ | ------------------------------------------------------------ | ----------------- |
| **事务**     | 支持。 每条SQL语言都默认封装成事务，自动提交。最好把多条SQL语言放在begin和commit之间，组成一个事务 | 不支持            |
| **外键**     | 支持。 将拥有外键的InnoDB表转成MyISAM会失败报错              | 不支持            |
| **锁**       | 表级锁、行级锁（默认）。 行锁实现在索引上，不是锁在物理行记录上。若访问没有命中索引，行锁退化为表锁。 | 表级锁 并发量低。 |
| **崩溃恢复** | 支持                                                         | 不支持            |

**MyISAM占优势的项**

| **项**       | **InnoDB** | **MyISAM** |
| ------------ | ---------- | ---------- |
| **全文索引** | 不支持     | 支持       |

注意：从MySQL5.6之后，InnoDB也支持全文索引了。

**使用场景**

| **InnoDB**               | **MyISAM**                                 |
| ------------------------ | ------------------------------------------ |
| 并发高或需要事务的地方。 | 读操作远远超过写操作，且不需要事务的地方。 |
